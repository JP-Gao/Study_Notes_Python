#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage[BoldFont,SlantFont,CJKnumber,fallback]{xeCJK}%使用TexLive自带的xeCJK宏包，并启用加粗、斜体、CJK数字和备用字体选项
\setCJKmainfont{Songti SC}%设置中文衬线字体,若没有该字体,请替换该字符串为系统已有的中文字体,下同
\setCJKsansfont{STXihei}%中文无衬线字体
\setCJKmonofont{SimHei}%中文等宽字体
%中文断行和弹性间距在XeCJK中自动处理了
%\XeTeXlinebreaklocale “zh”%中文断行
%\XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt%左右弹性间距
\usepackage{indentfirst}%段落首行缩进

%%%%%%%%%%%
\usepackage{color}
\usepackage{xcolor}
% \definecolor{keywordcolor}{rgb}{0.8,0.1,0.5}
\usepackage{listings}
\lstset{breaklines}%这条命令可以让LaTeX自动将长的代码行换行排版
\lstset{extendedchars=false}%这一条命令可以解决代码跨页时，章节标题，页眉等汉字不显示的问题
\lstset{language= R, %用于设置语言为C++
%背景框
framexleftmargin=10mm,
frame=none,
%背景色
%backgroundcolor=\color[rgb]{1,1,0.76},
backgroundcolor=\color[RGB]{245,245,244},
%样式
keywordstyle=\bf\color{blue},
identifierstyle=\bf,
numberstyle=\color[RGB]{0,192,192},
commentstyle=\it\color[RGB]{0,96,96},
stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},
%显示空格
showstringspaces=false,
xleftmargin=2em, %边距
xrightmargin=2em,
aboveskip=1em
}


%%%%%%%%%%%%

\usepackage[multidot]{grffile}
\setlength{\parindent}{2em}%缩进两个字符
\end_preamble
\use_default_options true
\begin_modules
eqs-within-sections
figs-within-sections
tabs-within-sections
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package auto
\inputencoding utf8-plain
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format pdf4
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 3
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks true
\pdf_backref section
\pdf_pdfusetitle true
\pdf_quoted_options "unicode=false"
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 0
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 0
\use_package mhchem 1
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Ads
\end_layout

\begin_layout Author
Fan Yang
\end_layout

\begin_layout Date
\begin_inset Foot
status open

\begin_layout Plain Layout
First version: July
\begin_inset Formula $20{}^{th}$
\end_inset

, 2016
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
Reference
\end_layout

\begin_layout Itemize
Recommender System - an Introduction
\end_layout

\begin_deeper
\begin_layout Itemize
DIETMAR JANNACH Technische Universit¨at Dortmund MARKUS ZANKER Alpen-Adria
 Universit¨at Klagenfurt ALEXANDER FELFERNIG Technische Universit¨at Graz
 GERHARD FRIEDRICH Alpen-Adria Universit¨at Klagenfurt
\end_layout

\end_deeper
\begin_layout Subsubsection
AB test
\end_layout

\begin_layout Standard
https://www.dynamicyield.com/2014/08/ab-testing-case-studies/
\end_layout

\begin_layout Part
ML
\end_layout

\begin_layout Enumerate
The Dimensionality of feature space is high.
 There are bunch of media features such as: exchange, publisher, app/website
 placement features, time of day, day of week, ad size etc.
 We also have several users features including: geo (city, state, country)
 and system-based features such as: device, connection, browser, OS etc.
 You can also grab extra user demographics from 3rd party data providers.
 
\end_layout

\begin_layout Enumerate
The well-known Rarity problem where there are a very few clicks and even
 much less conversions.
 To put this in perspective you might have a CTR around 0.08% to 0.11% in
 the best case.
 Now multiply this with another 10% conversion rate which give us a conversion
 rate in the range of 0.008%!
\end_layout

\begin_layout Section
Real-Time Bidding (RTB)
\end_layout

\begin_layout Standard
The first area of mobile advertising which can be improved by machine learning
 (ML) is Real-Time Bidding (RTB) traffic.
 In an RTB environment, Demand-Side Platforms (DSPs) need to determine the
 optimal amount to bid on every single specific impression.
 Most RTB-enabled exchanges will only allow a maximum response latency of
 100 milliseconds, meaning that a data-driven assessment of the impression
 has to be generated within an extremely short amount of time.
\end_layout

\begin_layout Standard
In order to determine how much to bid, the algorithm needs to assess the
 probability of the impression resulting in good performance metrics, such
 as 
\end_layout

\begin_layout Enumerate
Click-through rate (CTR), 
\end_layout

\begin_layout Enumerate
Conversion/install rate (CR/IR),
\end_layout

\begin_layout Enumerate
and even post-install events that enable to approximate Lifetime Value (LTV).
\end_layout

\begin_layout Standard
This assessment is done programmatically, utilizing data provided with the
 impression, either from the publisher or from a data management platform
 (DMP), as well as first party data from the advertiser as input.
\end_layout

\begin_layout Subsection
How
\end_layout

\begin_layout Standard

\series bold
Representation for solutions is the hardest:
\end_layout

\begin_layout Itemize
Design the cost function / Revenue Function, which elements to be included,
 how to quantify it.
\end_layout

\begin_layout Itemize
More complicated case: There is diminishing return: Revenue Function per
 account may decrease when quantity increases.
\end_layout

\begin_layout Subsection
Clustering Customer / Targeting
\end_layout

\begin_layout Section
Segmentation vs.
 Personalization in Recommendation
\end_layout

\begin_layout Itemize
Segmentation approch treat customers into groups, and biuld models on the
 group level.
\end_layout

\begin_deeper
\begin_layout Itemize
The process of analyzing segmented visitors can be thrilling, because it’s
 an opportunity to uncover some of the truths behind the numbers
\end_layout

\begin_layout Itemize
Better understanding, easier to tell a business story.
\end_layout

\begin_layout Itemize
Remember: Storytelling Means Everything to Your Data
\end_layout

\begin_layout Itemize
BUT, labels on customers may not be clear! Segmentation may be overlapping.
\end_layout

\end_deeper
\begin_layout Itemize
Personalalization approch: biuld model directly on the customer level, so
 those featuers used in segmentation are just features for individuals.
\end_layout

\begin_deeper
\begin_layout Itemize
Getting personalization right is much easier when there’s a solid understanding
 of the characteristics of the segments it is based on.
\end_layout

\begin_layout Itemize
You can use Personalalization models to predict and then use Segmentation
 data to tell story.
\end_layout

\end_deeper
\begin_layout Part
Bid Price
\end_layout

\begin_layout Standard
Don’t try for the cheapest clicks or impressions—You'll reach people that
 are easier to reach, but don’t necessarily provide the value you expect.
 
\end_layout

\begin_layout Itemize
CPM: Definition of 'Cost Per Thousand - CPM' The price of 1,000 advertisement
 impressions on one webpage.
 If a website publisher charges $2 CPM, that means an advertiser must pay
 $2 for every 1,000 impressions of its ad.
 The "M" in CPM represents the roman numeral for 1,000.
\end_layout

\begin_layout Itemize
CPE (cost per engagement): 
\end_layout

\begin_deeper
\begin_layout Itemize
in CPE model, the impressions are free.
 When you involve an advertiser in a Cost per Engagement model, the advertiser
 will pay only when a user engages with an ad unit.
 Engagemnt is something, which the advertisers and the publisher have to
 sit together and decide on.
 IN CPE model, it can be considered as engagement when,
\end_layout

\begin_layout Enumerate
User hovers over the ad and the whole ad unit open up displaying the creative
 
\end_layout

\begin_layout Enumerate
If the ad is in the form of a poll, engagement happens only when the user
 takes the poll 
\end_layout

\begin_layout Enumerate
Some CPE based ads might be in the form of a product tour, which if an user
 takes, can be considered as engagement 
\end_layout

\begin_layout Enumerate
Online games in the form of ad.
\end_layout

\end_deeper
\begin_layout Part
Recommendation: Collaborative Filtering
\end_layout

\begin_layout Standard
The main idea of collaborative recommendation approaches is to 
\end_layout

\begin_layout Enumerate
exploit information about the past behavior or the opinions of an existing
 user community 
\end_layout

\begin_layout Enumerate
for predicting which items the current user of the system will most probably
 like or be interested in.
\end_layout

\begin_layout Itemize
Input of data: A user - item rating matrix
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

UserID / item rating 1 - 5
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

User1 	3 1 2 3 3
\end_layout

\begin_layout Plain Layout

User2 	4 3 4 3 5
\end_layout

\begin_layout Plain Layout

User3 	3 3 1 5 4
\end_layout

\begin_layout Plain Layout

User4 	1 5 5 2 1
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
We may also know the rating of Alice for item 1-4, but not knwo his rating
 on 5 (this is the 
\begin_inset Formula $y$
\end_inset

 to be forecasted)
\end_layout

\end_deeper
\begin_layout Itemize
Goal: 
\end_layout

\begin_deeper
\begin_layout Itemize
a (numerical) prediction indicating to what degree the current user will
 like or dislike a certain item
\end_layout

\begin_deeper
\begin_layout Itemize
Here in example, the goal is to predict the item 5 rating from 
\end_layout

\end_deeper
\begin_layout Itemize
a list of n recommended items.
 Such a top-N list should, of course, not contain items that the current
 user has already bought
\end_layout

\end_deeper
\begin_layout Section
User-based nearest neighbor 
\end_layout

\begin_layout Subsection
Similarity Measure weighted rating
\end_layout

\begin_layout Standard
The rating of item 5 for Alice is the weighted rating of item 5 from all
 other users, weighted by imilarities between Alice with each of the users.
\end_layout

\begin_layout Standard
Use the available ratings from item 1-4 for all users to calculate similarities
 between Alice with each of the user
\end_layout

\begin_layout Itemize
Similarity Measture between two users 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

: 
\series bold
Pearson’s correlation coefficient (from -1 to 1)
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
sim(a,b)=\frac{\sum_{p\in P}(r_{a,p}-\bar{a})(r_{b,p}-\bar{b})}{\sqrt{\sum_{p\in P}(r_{a,p}-\bar{a})^{2}}\sqrt{\sum_{p\in P}(r_{b,p}-\bar{b})^{2}}}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Cosin Similarity
\end_layout

\begin_deeper
\begin_layout Itemize
adjusted cosine similarity is eactly same as 
\series bold
Pearson’s correlation coefficient
\end_layout

\begin_layout Itemize
20 to 50 neighbors seems reasonable
\end_layout

\end_deeper
\begin_layout Itemize
Other metrics can be used as features
\end_layout

\begin_deeper
\begin_layout Itemize
such as gender, age, education, interests, or other available information
 that can help to classify the user
\end_layout

\end_deeper
\begin_layout Subsection
Applications
\end_layout

\begin_layout Itemize
Neighborhood selection to reduce sample size: 
\end_layout

\begin_deeper
\begin_layout Itemize
The common techniques for reducing the size of the neighborhood are to define
 a specific minimum threshold of user similarity or to limit the size to
 The common techniques for reducing the size of the neighborhood are to
 define a specific minimum threshold of user similarity or to limit the
 size to
\end_layout

\begin_layout Itemize
a neighborhood of 20 to 50 neighbors seems reasonable”
\end_layout

\end_deeper
\begin_layout Itemize
Implicit and explicit ratings
\end_layout

\begin_deeper
\begin_layout Itemize
When a customer buys an item, for instance, many recommender systems interpret
 this behavior as a positive rating.
\end_layout

\begin_layout Itemize
The system could also monitor the user’s browsing behavior.
 If the user retrieves a page with detailed item information and remains
 at this page for a longer period of time, for example, a recommender could
 interpret this behavior as a positive orientation toward the item.
\end_layout

\end_deeper
\begin_layout Itemize
when there are relatively few ratings available
\end_layout

\begin_deeper
\begin_layout Itemize
use other metrics like age
\end_layout

\begin_layout Itemize
use implicit ratings
\end_layout

\begin_layout Itemize
assign default values to items that only one of the two users has rated
 (and possibly also to some additional items) to improve the prediction
 quality of sparse rating databases
\end_layout

\end_deeper
\begin_layout Section
Item-based nearest neighbor
\end_layout

\begin_layout Standard
Definition: compute predictions using the similarity between items and not
 the similarity between users.
\end_layout

\begin_layout Standard
In the example, we see that the ratings for 
\series bold
Item5 (3, 5, 4, 1)
\series default
 are similar to the ratings of 
\series bold
Item1 (3, 4, 3, 1)
\series default
 and there is also a partial similarity 
\series bold
Item4 (3, 3, 5, 2).
\end_layout

\begin_layout Standard
Formally, we can predict the rating for user 
\begin_inset Formula $u$
\end_inset

 for a product 
\begin_inset Formula $p$
\end_inset

 as follows: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
pred(\mu,p)=\frac{\sum_{i\in rateItems(\mu)}sim(i,p)\times r_{u,i}}{\sum_{i\in rateItems(\mu)}}
\]

\end_inset


\end_layout

\begin_layout Section
Model-Based
\end_layout

\begin_layout Standard
Collaborative recommendation techniques are often classified as being either
 memory-based or model-based.
 
\end_layout

\begin_layout Standard
The traditional user-based technique is said to be memory-based because
 the original rating database is held in memory and used directly for generating
 the recommendations.
 
\end_layout

\begin_layout Standard
In model-based approaches, on the other hand, the raw data are first processed
 offline, as described for itembased filtering or some dimensionality reduction
 techniques.
 At run time, only the precomputed or “learned” model is required to make
 predictions.
\end_layout

\begin_layout Subsection
LSI - SVD
\end_layout

\begin_layout Standard
Benifits: create a small matrix which is easility implemented online / poduction.
 No need to remeber the whole large matrix.
\end_layout

\begin_layout Enumerate
Use the SVD on the ItemRating-User (note that now User is the column and
 item is the row ) matrix.
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula 
\[
M=U\Sigma V^{T}
\]

\end_inset


\end_layout

\begin_layout Enumerate
where 
\begin_inset Formula $U=m\times m$
\end_inset

 represent the item and 
\begin_inset Formula $V=n\times n$
\end_inset

 represent the users, and 
\begin_inset Formula $\Sigma$
\end_inset

 is a 
\begin_inset Formula $m\times n$
\end_inset

 matrix, with 
\begin_inset Formula $p$
\end_inset

 diagnoal values.
\end_layout

\end_deeper
\begin_layout Enumerate
Thus we can map Alice's profile point 
\begin_inset Formula $A$
\end_inset

 (
\begin_inset Formula $q\times1$
\end_inset

 matrix with 
\begin_inset Formula $q$
\end_inset

 items) to the 
\begin_inset Formula $p$
\end_inset

 dimention world assess
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula 
\[
A_{P}=A^{T}U\Sigma^{-1}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Then you use Neighborhood of users/items in the 
\begin_inset Formula $p$
\end_inset

 dimention to see which user is close to A
\end_layout

\begin_layout Part
Recommendation: Content-based 
\end_layout

\begin_layout Section
LSI: Application to Recommend who to Follow
\end_layout

\begin_layout Standard
See
\series bold
\emph on
 Content-based Dimensionality Reduction for Recommender Systems Panagiotis
 Symeonidis 
\series default
\emph default
for clear reference
\end_layout

\begin_layout Standard
Purpose is to recommend the user 
\begin_inset Formula $A$
\end_inset

 who to follow.
 You select 
\begin_inset Formula $N$
\end_inset

 users as your training set.
\end_layout

\begin_layout Itemize
Construct user's following behavior as matrix 
\begin_inset Formula $M$
\end_inset

: all users as followers are in the row, all users as followees are in the
 column.
 If a follower in the row follows a user in the column, then the value is
 1, othervice it is 0.
\end_layout

\begin_deeper
\begin_layout Enumerate
Then you can use 
\begin_inset Formula $SVD$
\end_inset

 to map these follower-followee relations from 
\begin_inset Formula $p$
\end_inset

 dimention to 
\begin_inset Formula $q$
\end_inset

 dimention, thus you get the lower rank of the representation
\end_layout

\begin_layout Enumerate
Then use the dimention reduction mapping to map user 
\begin_inset Formula $A$
\end_inset

 to the 
\begin_inset Formula $q$
\end_inset

 dimention
\end_layout

\begin_layout Itemize
To reduce the complexity of computation, you can trim 
\begin_inset Formula $M$
\end_inset

 to only select long time users who follow at least 10 users all being followed
 by at least 10 users.
\end_layout

\begin_layout Itemize
But this method can only work if 
\begin_inset Formula $A$
\end_inset

 already has a lot of followings
\end_layout

\end_deeper
\begin_layout Itemize
Normally we already assign labels to our users, those labels could: professional
 user / advertisers / opinion leader / democratic-republican / demographics
 / celebrities / Like music / Like computer science.
 Then you can construct a matrix with rows as users and columns as twitters,
 and do the SVD/LSI and KNN.
\end_layout

\begin_deeper
\begin_layout Itemize
This requires a lot of prework: you need to biuld a clustering model to
 assign the labels.
\end_layout

\begin_layout Itemize

\series bold
That means you model depend on other model, which is the labelling model.
\end_layout

\end_deeper
\begin_layout Section
Cold Start problem
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $A$
\end_inset

 is a new user: you need some cold start techniques.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
You have to let 
\begin_inset Formula $A$
\end_inset

 to self identify his interest, 
\end_layout

\begin_layout Enumerate
let him to choose who to follow at the very begining.
\end_layout

\begin_layout Enumerate
Or just give him the most popular celebrities and let him to follow.
\end_layout

\end_deeper
\begin_layout Section
Probalistic Method
\end_layout

\begin_layout Subsection
Naiv Bayes
\end_layout

\begin_layout Standard
To predict whether User 
\begin_inset Formula $A$
\end_inset

 will like use 
\begin_inset Formula $B$
\end_inset

, then the training data are all other 
\begin_inset Formula $N$
\end_inset

 with 
\begin_inset Formula $q$
\end_inset

 features (
\begin_inset Formula $F$
\end_inset

) that either follow or not follow 
\begin_inset Formula $B$
\end_inset

(0, or 1), then the likelihood of 
\begin_inset Formula $A$
\end_inset

 like 
\begin_inset Formula $B$
\end_inset

 is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(B=1|F_{A})\sim P(F_{A}|B=1)\times P(B=1)=\prod_{j}^{q}P(f_{j}|B=1)\times P(B=1)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $P(f_{j}|B=1)=\phi_{j}$
\end_inset

 can get from max likelihood of data
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\prod_{i}^{N}\left[\prod_{j}^{q}\phi_{j}^{i=1}(1-\phi_{j})^{i=1}P(i)\right]
\]

\end_inset


\end_layout

\begin_layout Subsection
Logistic
\end_layout

\begin_layout Section
Knowdge-based 
\end_layout

\begin_layout Section
link prediction, which analyzes who your friends are friends with.
 
\end_layout

\begin_layout Part
Ad Basis
\end_layout

\begin_layout Description
Budge: money that advertiers ready to spend -- Demand
\end_layout

\begin_layout Description
Inventory: advertisement space that Facebook/Twitter is ready to sell to
 advertisers -- Supply
\end_layout

\begin_layout Subsection
Types of Apps
\end_layout

\begin_layout Itemize
Apps that are a sales channel for a real-world product (Amazon, Booking.com,
 Uber), in other words: “transactional apps”
\end_layout

\begin_deeper
\begin_layout Itemize
For transactional apps, key metrics such as Conversion Rate and Basket Value
 are both widely established and well understood as they follow the same
 e-commerce logic known from selling on websites.
 
\end_layout

\begin_layout Itemize
Basket value is the definition of the total sum of the products purchased
\end_layout

\end_deeper
\begin_layout Itemize
Apps where the app itself is the product (Facebook, WhatsApp, Twitter),
 in other words “product apps”
\end_layout

\begin_deeper
\begin_layout Itemize
Product apps, however, often use a rather wild set of metrics:
\series bold
 Installs, User Base, Virality, Stickiness, Retention
\series default
 
\end_layout

\begin_layout Itemize
measured in any variety of ways to describe their app’s commercial traction.
 
\end_layout

\end_deeper
\begin_layout Section
Social Network
\end_layout

\begin_layout Subsection
Creators in Social Network
\end_layout

\begin_layout Standard
The worry is that the "creators," that is the celebrities, journalists,
 and video-makers who regularly post stuff on Twitter, might decide that
 Twitter isn't the hotspot it once was, and could decamp to a different
 online service for their daily musings and content postings.
 
\end_layout

\begin_layout Subsection
Types of Users: the Goldn Rule
\end_layout

\begin_layout Itemize
1 – number of followers the user has
\end_layout

\begin_layout Itemize
2 – number of tweets they’ve made
\end_layout

\begin_layout Itemize
3 – the number of people that user is following
\end_layout

\begin_layout Standard
If 1 is greater than 3 (let’s call it a “positive ratio”), it could be worth
 clicking through to that person’s profile.
 If 1 is much greater than 3, they most certainly are at least worth looking
 at.
 If 3 is greater than 1 (the “negative ratio”) by a large margin, the likelihood
 that they’re a spammer or marketer is pretty good 
\end_layout

\begin_layout Subsection
Measure of Interaction for a Social Network
\end_layout

\begin_layout Standard
IPM (interactions per message): This basically tells you the average chance
 of engagement per fan/follower.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
IPM=\sum_{-30d}^{now}\frac{likes_{t}+replies_{t}+shares_{t}}{message_{t}\times N_{fans}}
\]

\end_inset


\end_layout

\begin_layout Standard
So if we really want to measure engagement accurately then you only want
 to take into account a couple of things: 
\end_layout

\begin_layout Enumerate
How many unique people actually "engaged" or otherwise have taken an action
 based on your content 
\end_layout

\begin_layout Enumerate
How many unique people saw your content before engaging 
\end_layout

\begin_layout Standard
And that's how we ended up with IPV (interactions per unique view) which
 is measured on content level, but can easily be scaled up to a brand level
 serving as an average of all underlying content.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
IPM=\sum_{-30d}^{now}\frac{likes_{t}+replies_{t}+shares_{t}}{views}
\]

\end_inset


\end_layout

\begin_layout Standard
publishing a message doesn't necessarily mean that all your fans end up
 seeing it.
 And the view rate helps you understand to how many people of your total
 fan base saw your content in the end (and thus how well it performed in
 Facebook's Edge Rank algorithm).
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
VRc=\frac{views_{unique}}{fans_{t}}
\]

\end_inset


\end_layout

\begin_layout Subsection
Clustering Social Networks
\end_layout

\begin_layout Section
Online Shoping
\end_layout

\begin_layout Subsection
Factors to use to differentiate an online shopper
\end_layout

\begin_layout Enumerate
Revenue impact
\end_layout

\begin_layout Enumerate
Engagement or action taken: whether to share a product
\end_layout

\begin_layout Enumerate
Visitors with past conversions versus no conversions
\end_layout

\begin_deeper
\begin_layout Enumerate
segment converters and non-converters based on traffic sources, such as
 paid versus organic search, display advertising, specific referrals and
 so on.
\end_layout

\end_deeper
\begin_layout Enumerate
Customer intent
\end_layout

\begin_deeper
\begin_layout Enumerate
Researchers: Highly motivated, goal-driven shoppers who are looking to learn
 and become educated about a specific product.
 These customers tend to spend a lot of time exploring specific product
 pages, learning about features, prices, delivery terms, etc.
\end_layout

\begin_layout Enumerate
Browsers
\end_layout

\begin_layout Enumerate
Product-focused shoppers: Highly-focused, goal-driven shoppers who know
 exactly what they’re looking for.
\end_layout

\begin_layout Enumerate
Bargain hunters
\end_layout

\end_deeper
\begin_layout Section
Customer Enagament 
\end_layout

\begin_layout Subsection
Measure of User Engagement
\end_layout

\begin_layout Itemize
Usage / Popularity:
\end_layout

\begin_deeper
\begin_layout Itemize
DAU - All unique users who have launched the App on that day
\end_layout

\begin_deeper
\begin_layout Itemize
Each App:Device pair is given a unique ID (generated by Apteligent) at the
 time the end-user installs the app on their device and launches it for
 the first time
\end_layout

\end_deeper
\begin_layout Itemize
MAU - All unique users who have launched the App at least once in that month
\end_layout

\begin_deeper
\begin_layout Itemize
Typically, metrics are measured by counting the number of unique users during
 a specific measurement period, such as within the previous 30 days.
\end_layout

\end_deeper
\begin_layout Itemize
Visits & pageviews are susceptible to all sorts of external factors, like
 SEO, SEM, press, seasonal traffic swings, etc
\end_layout

\end_deeper
\begin_layout Itemize
Stickness/Loyalty: 
\end_layout

\begin_deeper
\begin_layout Itemize
SessionsL Every time any user, not just a unique user, opens your app, that
 counts as a session.
\end_layout

\begin_layout Itemize
DAU / MAU is the standard
\end_layout

\begin_layout Itemize
Time On Site and Pages/Visit are good, but will oscillate with design changes,
 e.g.
 paginating long text articles will increase Pages/Visit without being any
 better for your site.
 It may also mean that user may struggle to find what they need in your
 web.
\end_layout

\begin_layout Itemize
Click Depth: Average number of page views per visit.
 
\end_layout

\end_deeper
\begin_layout Itemize
Interaction (for social media)
\end_layout

\begin_deeper
\begin_layout Standard
\begin_inset Formula 
\[
IPM=\sum_{-30d}^{now}\frac{likes_{t}+replies_{t}+shares_{t}}{message_{t}\times N_{fans}}
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Retention: very long term stickness
\end_layout

\begin_deeper
\begin_layout Itemize
like a negative log
\end_layout

\begin_layout Itemize
churn rate: the annual percentage rate at which customers stop subscribing
 to a service or employees leave a job.
\end_layout

\end_deeper
\begin_layout Itemize
Money: 
\end_layout

\begin_deeper
\begin_layout Itemize
Conversion Rate
\end_layout

\begin_layout Itemize
ARPDAU: The Average Revenue Per Daily Active User, or ARPDAU,
\end_layout

\begin_layout Itemize
ARPPU: Average Revenue Per Paying User (ARPPU) measures only the subset
 of users who have completed a purchase in a game.
 This metric can vary dramatically based on game genre.
 Hardcore games tend to have higher monetization metrics like ARPPU, but
 they also lack the mass appeal of more casual games.
\end_layout

\end_deeper
\begin_layout Itemize
Growth:
\end_layout

\begin_deeper
\begin_layout Itemize
Depending on which particular aspect you want to focus on, any metrics above
 in their delta forms are good to measure growth.
 
\end_layout

\end_deeper
\begin_layout Standard

\series bold
Which one to choose: It depends on:
\end_layout

\begin_layout Enumerate
Different stages of consumer engagement
\end_layout

\begin_deeper
\begin_layout Enumerate
If you just want to raise awareness of a product, then number of views
\end_layout

\begin_layout Enumerate
If you care about how to 
\series bold
transforming
\series default
 the views to revenues, then click per view
\end_layout

\end_deeper
\begin_layout Enumerate
What's is the nature of the product
\end_layout

\begin_deeper
\begin_layout Enumerate
For a product like google: Visitor Recency.
 Time On Site may be misleading
\end_layout

\begin_layout Enumerate
For a product like facebook, Interaction-related measure.
\end_layout

\end_deeper
\begin_layout Subsection
Campaign Objective
\end_layout

\begin_layout Standard
As a merchant (now the customers of Facebook/Google are merchants):
\end_layout

\begin_layout Itemize
Increase people's awareness of your brand or business: For people didn't
 know you
\end_layout

\begin_deeper
\begin_layout Itemize
Boost post / page /tweet
\end_layout

\end_deeper
\begin_layout Itemize
Find potential customers for your business: For people already know you,
 let them know you better or start to love/engage with you
\end_layout

\begin_deeper
\begin_layout Itemize
Promote your Facebook event to increase your attendance.
 
\end_layout

\begin_layout Itemize
Promote videos that show behind-the-scenes footage, product launches or
 customer stories to raise awareness about your brand.
 
\end_layout

\end_deeper
\begin_layout Itemize
Drive conversions or sales for your business: 
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Direct Response Marketing
\series default
 is a type of marketing designed to generate an immediate response from
 consumers, where each consumer response and purchase can be measured, and
 attributed to individual advertisements.
\end_layout

\begin_layout Itemize
Buy
\end_layout

\begin_layout Itemize
Register.
\end_layout

\begin_layout Itemize
Claim the offer
\end_layout

\end_deeper
\begin_layout Subsection
Danger of DAU
\end_layout

\begin_layout Standard
Well, not necessarily.
 You just launched, got a press bump, and got featured.
 If all a user has to do is download your app and open it once, then your
 “active users” are bound to go up as registrations increase—people are
 curious and downloading an app is a low-friction transaction with zero
 commitment.
\end_layout

\begin_layout Standard

\series bold
Downloading an app is a low-friction transaction with zero commitment.
\end_layout

\begin_layout Itemize
It doesn’t measure real usage of your app: The danger of defining your “active
 user” by a minimal metric like logins is that you’re just seeing a reflection
 of press and hype.
 
\end_layout

\begin_layout Itemize
Suffer volatility / Essentially short term: :While your DAU is skyrocketing,
 the number of people playing songs is not.
 People are downloading your app and logging in, but most of them aren’t
 really using it the way it’s meant to be used.
 If you’re only paying attention to your DAU, you’ll miss the fact that
 real usage is dropping off—you won’t hear the canary in the coal mine of
 your app.
\end_layout

\begin_layout Subsection
Customer Lifetime Value (CLV / LTV)
\end_layout

\begin_layout Itemize
customer lifetime value (CLV or often CLTV), lifetime customer value (LCV),
 or life-time value (LTV) 
\end_layout

\begin_layout Standard
Lifetime value is typically used to judge the appropriateness of the costs
 of acquisition of a customer.
\end_layout

\begin_layout Standard
Simple method: 
\begin_inset Formula 
\[
LTV=ARPU*lifetime
\]

\end_inset


\end_layout

\begin_layout Standard
Bring 
\begin_inset Formula $t$
\end_inset

 into ARPU 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
LTV=\sum_{t=0}^{\infty}ARPU(t)
\]

\end_inset


\end_layout

\begin_layout Standard
OR
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
LTV=\sum_{n}^{N}(retention_{n})\times ARPU
\]

\end_inset


\end_layout

\begin_layout Standard
How to calculate social LTV for those celebrities.
\end_layout

\begin_layout Subsection
Deeper Analysis of Usage
\end_layout

\begin_layout Standard
If you want to understand what’s going on in your app, you’ll do a full-scale
 stickiness audit:
\end_layout

\begin_layout Itemize

\series bold
Find Out Where/Which Part/Which Feature Most Usage Happens.
 Identify Features That Lead To Retention
\end_layout

\begin_layout Standard
At Facebook, Chamath ran the Growth team like a laboratory, constantly experimen
ting and trying new things to see what worked.
 What all their testing, experimenting and analyzing taught them, in the
 end, was one simple fact: that if users added 7 friends in 10 days they
 were retained with Facebook.
\end_layout

\begin_layout Standard
From then on, the entire company was united around a single goal: 7 friends
 in 10 days.
 That was the sweet spot for the delivery of Facebook’s core value.
\end_layout

\begin_layout Section
Web & Ad
\end_layout

\begin_layout Subsection

\series bold
Impression (online media) 
\end_layout

\begin_layout Standard
An impression (in the context of online advertising) is when an ad is fetched
 from its source, and is countable.
 Whether the ad is clicked is not taken into account.[1] Each time an ad
 is fetched it is counted as one impression.[2]
\end_layout

\begin_layout Standard
Because of the possibility of click fraud, robotic activity is usually filtered
 and excluded, and a more technical definition is given for accounting purposes
 by the IAB, a standards and watchdog industry group: "Impression" is a
 measurement of responses from a Web server to a page request from the user
 browser, which is filtered from robotic activity and error codes, and is
 recorded at a point as close as possible to opportunity to see the page
 by the user.[3][4]
\end_layout

\begin_layout Subsection
Cost per impression (CPI) vs Cost per click (CPC)
\end_layout

\begin_layout Standard
Cost per impression (CPI), or "Cost per thousand impressions" (CPM)
\end_layout

\begin_layout Subsection

\series bold
Sessio
\series default
n
\end_layout

\begin_layout Standard

\series bold
sessio
\series default
n is defined as user activity that begins with a query and ends with 30
 minutes of inactivity on the search engine/web page
\end_layout

\begin_layout Subsection
Click-Through Rate (CTR rate)
\end_layout

\begin_layout Itemize
Click-through rate (CTR) is the ratio of users who click on a specific link
 to the number of total users who view a page, email, or advertisement.
\end_layout

\begin_layout Standard
CTR is a metric that is used to analyze emails, webpages and online search
 result pages (Google, Bing, Yahoo etc).
 CTR is normally used to measure the success of marketing efforts.
\end_layout

\begin_layout Standard
CTR EXAMPLES
\end_layout

\begin_layout Standard
Some common examples of where CTR can be measured include:
\end_layout

\begin_layout Standard
A call-to-action link in an email A hyperlink on a landing page .A PPC ad
 on a Google search results page
\end_layout

\begin_layout Standard
Click-through rate is calculated by the number of clicks on an element divided
 by the number of people who have seen that element
\end_layout

\begin_layout Standard
CTR should not be mistaken for conversion rate.
 Conversion rate is the percentage of people who take a desired action.
 CTR, on the other hand, is normally associated with an action leading up
 to a conversion.
\end_layout

\begin_layout Standard
CTR can be used to gain useful insights in A/B testing, as a secondary metric
 alongside the primary conversion metric.
 
\end_layout

\begin_layout Subsection
Ad Viewability
\end_layout

\begin_layout Standard
WHAT IS AD VIEWABILITY?
\end_layout

\begin_layout Standard
Ad viewability is the concept of how visible ads on a website or mobile
 app are to users.
 For an ad to be considered “viewed”, at least 50% of the banner or creative
 must display on screen for more than one second, as defined by the Internet
 Advertising Bureau’s standard for what consists a viewable impression.
\end_layout

\begin_layout Standard
Ad viewability is a relatively new concept in digital advertising, but has
 become a hot topic ever since a report from comScore showed that 54% of
 display ads were not being seen, despite advertisers paying for them.
\end_layout

\begin_layout Standard
Over time, however, advertisers began to question the practice of using
 ads served as a proxy for ads viewed.
 For example, it occurred to them that if an ad appeared 
\series bold
below the fold
\series default
 at the bottom of a webpage, but a user never scrolled down far enough to
 see it, that impression should not be counted.
\end_layout

\begin_layout Standard
Publishers can also make their sites mobile-friendly by using responsive
 templates that resize according to the device where it is being viewed.
 This guarantees a good user experience no matter the device (tablet, phone
 or desktop).
\end_layout

\begin_layout Standard
Ad viewability also improves through good design principles: a clear visual
 hierarchy, symmetry and pleasing proportions, white space and clean design.
\end_layout

\begin_layout Standard
Another key consideration for ad viewability is speed.
 Sites that are laden with ads from multiple ad networks can typically take
 a long time to load, which can result in a lower ad viewability as users
 click away before the ads load.
 Techniques for speeding up ad delivery can greatly improve ad viewability.
\end_layout

\begin_layout Subsection
Search Engine Marketing (SEM / SEO)
\end_layout

\begin_layout Standard
Search engine marketing is a form of Internet marketing that involved the
 promotion of websites by increasing their visibility in search engine results
 pages (SERPS) through optimization and advertising.” SEM includes SEO tactics,
 as well as several other search marketing tactic
\end_layout

\begin_layout Subsection
Headline Testing
\end_layout

\begin_layout Standard
WHAT IS HEADLINE TESTING?
\end_layout

\begin_layout Standard
“Headline testing” refers to the process of developing multiple title variations
 for an article or piece of online media, which can then be tested on multiple
 audience segments of to determine which one performs the best.
\end_layout

\begin_layout Subsection
Landing page 
\end_layout

\begin_layout Standard
In online marketing, a landing page, sometimes known as a "lead capture
 page" or a "lander", is a single web page that appears in response to clicking
 on a search engine optimized search result or an online advertisement.
 The landing page will usually display directed sales copy that is a logical
 extension of the advertisement, search result or link.
\end_layout

\begin_layout Standard
Landing pages are often linked to from social media, email campaigns or
 search engine marketing campaigns in order to enhance the effectiveness
 of the advertisements.
 
\end_layout

\begin_layout Subsection
Sales Funnel
\end_layout

\begin_layout Standard
A sales funnel is a visual metaphor for the path taken by a potential customer
 as he or she moves towards becoming a customer.
\end_layout

\begin_layout Subsection

\series bold
Below the fold / above the fold
\end_layout

\begin_layout Subsection
Conversion (rate)
\end_layout

\begin_layout Standard
A conversion occurs when a user completes some predetermined action on your
 site.
 Conversions do not have to be tied to monetary goals, and common examples
 are when a user completes an order, clicks a button, submits a lead generation
 form, reaches a specific page, or any other goal of interest.
\end_layout

\begin_layout Standard
IDENTIFYING AREAS TO OPTIMIZE
\end_layout

\begin_layout Itemize
Typically, you will want to begin optimizing the portion of your conversion
 funnel that receives the greatest amount of traffic or generates the greatest
 numbers of conversions.
 By focusing on these pages you will be able to see the results of your
 changes faster and have a larger impact on your business.
\end_layout

\begin_layout Itemize
Other potential places to start include your 
\end_layout

\begin_deeper
\begin_layout Enumerate
greatest amount of traffic/greatest numbers of conversions.
\end_layout

\begin_layout Enumerate
highest value pages or
\end_layout

\begin_layout Enumerate
pages that are underperforming compared to the rest of your site.
\end_layout

\begin_layout Itemize
Again, improving these areas can have the greatest immediate impact on your
 conversion goals.
\end_layout

\end_deeper
\begin_layout Itemize
For example, a clothing retailer may find that their page for hats receives
 a lot of traffic but has a conversion rate that is much lower than the
 rest of the site.
 By improving the conversion rate of that page, the retailer will be able
 to see a big improvement in sales for their CRO efforts.
\end_layout

\begin_layout Subsection
Call To Action
\end_layout

\begin_layout Itemize
A call to action (CTA) is a prompt on a website that tells the user to take
 some specified action.
 A call to action is typically written as a command, such as ‘Sign Up’ or
 ‘Buy Now’ and generally takes the form of a button or hyperlink.
\end_layout

\begin_layout Itemize
For example, on a blog the CTAs might look like:
\end_layout

\begin_deeper
\begin_layout Itemize
Read more articles
\end_layout

\begin_layout Itemize
Sign-up for our newsletter
\end_layout

\begin_layout Itemize
Support our sponsor
\end_layout

\begin_layout Itemize
Share on social media
\end_layout

\end_deeper
\begin_layout Itemize
Whereas on an ecommerce site, the CTAs may be more commercially focused:
\end_layout

\begin_deeper
\begin_layout Itemize
Add to cart
\end_layout

\begin_layout Itemize
Checkout
\end_layout

\begin_layout Itemize
Buy now
\end_layout

\begin_layout Itemize
Add to wishlist
\end_layout

\end_deeper
\begin_layout Itemize
Marketers employ a number of strategies for creating CTAs.
 Below is a list of some common ones:
\end_layout

\begin_deeper
\begin_layout Itemize
Good Design: A colorful button that contrasts with the color of the page
 is a good strategy to get the user’s attention.
\end_layout

\begin_layout Itemize
High Visibility: Because the call to action should be the most noticeable
 thing on the page, the font size should be large enough to command attention.
\end_layout

\begin_layout Itemize
Clear Benefit: Stating a clear benefit that the user will get from completing
 the transaction is an effective way to get them to click.
\end_layout

\begin_layout Itemize
Actionable Text: A call to action written in the imperative mood gives a
 clear and direct command of what to do.
\end_layout

\begin_layout Itemize
Short in Length: A good call to action should be a short phrase, not a sentence.
 Most are no longer than five words.
\end_layout

\begin_layout Itemize
Guarantees That Reduce Perceived Risk: Any type of money-back guarantee
 or short free trial period helps convince the user that there is little
 risk in completing the transaction.
\end_layout

\end_deeper
\begin_layout Subsection
Effect of robots on experimental results
\end_layout

\begin_layout Standard
For some websites robots are thought to provide up to half the pageviews
 on the site (Kohavi et al.
 2004).
 Since many robots have the same characteristics as human users it is difficult
 to clearly delineate between the two.
 Benign or simple robots can often be filtered by basic characteristics
 (e.g.
 user agent, IP address) but manymodern robots use sophisticated techniques
 to escape detections and filtering (Tan and Kumar 2002).
\end_layout

\begin_layout Part
A/B Test Math
\end_layout

\begin_layout Section
Tests
\end_layout

\begin_layout Subsection
T-test, used in A/B tests (single factor hypothesis tests):
\end_layout

\begin_layout Standard

\series bold
Used to in one sample, to test the sample mean.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T=\frac{\bar{O}_{B}-\bar{O}_{A}}{\hat{\sigma}_{d}}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\bar{O}_{B},\bar{O}_{A}$
\end_inset

 are the estimated OEC values (e.g., averages), σd is the estimated standard
 deviation of the difference between the two OECs,
\end_layout

\begin_layout Standard
The percent difference is calculated by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta\%=\frac{\bar{O}_{B}-\bar{O}_{A}}{\bar{O}_{A}}
\]

\end_inset


\end_layout

\begin_layout Standard
Can be used to establish whether there are statistically significant relationshi
ps between two categorical variables (nominal/ordinal)
\end_layout

\begin_layout Itemize
e.g.
 Is there a statistically significant relationship between skateboard ownership
 and sex? In other words, is skateboard ownership INDEPENDENT of sex? 
\end_layout

\begin_layout Subsection
Confidence intervals for absolute and percent effect
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
CILimits=OB−OA±1.96\times\tilde{σ}_{d}
\]

\end_inset


\end_layout

\begin_layout Itemize
For many online metrics, the difference in the means is so small that percent
 change has much more intuitive meaning than the absolute difference.
\end_layout

\begin_layout Itemize
However, forming a confidence interval around the percent change is not
 a straightforward extension of the confidence interval for the absolute
 effect.
 This is because we are now dividing by a random variable.
 
\end_layout

\begin_layout Itemize
Note that if the denominator is stochastically close to zero one or both
 endpoints will not exist.
 In practice, you shouldn’t calculate this interval if the confidence interval
 for the denominator contains zero.
\end_layout

\begin_layout Standard
Define the coefficient of variation of the two groups to be 
\begin_inset Formula $CV_{B}=\frac{\hat{\sigma}_{B}}{\bar{O}_{B}}$
\end_inset

.
\end_layout

\begin_layout Standard
CI for Percent Effect = 
\begin_inset Formula 
\[
(\Delta\%+1)\times\frac{1\pm1.96\times\sqrt{CV_{A}^{2}+CV_{B}^{2}-1.96^{2}\times CV_{A}^{2}\times CV_{B}^{2}}}{1-1.96\times CV_{A}^{2}}-1
\]

\end_inset


\end_layout

\begin_layout Standard
all, these confidence intervals are proportional to 
\begin_inset Formula $1/\sqrt{N}$
\end_inset

 when 
\begin_inset Formula $N$
\end_inset

 is the number of users, which is growing
\end_layout

\begin_layout Subsection
Chi Square Tests
\end_layout

\begin_layout Itemize
Pearson's chi-squared test (χ2) is a statistical test applied to sets of
 categorical data to evaluate how likely it is that any observed difference
 between the sets arose by chance.
\end_layout

\begin_layout Itemize
There are multi-samples 
\begin_inset Formula $n$
\end_inset

, each sample has observed number 
\begin_inset Formula $N_{i}$
\end_inset

 with a feature certain, and it is expected to be 
\begin_inset Formula $E_{i}$
\end_inset

.
\end_layout

\begin_layout Itemize
chi-squared test is to measure whether the feature is randomly distributed
 accross different samples.
\end_layout

\begin_layout Standard
The chi square statistic is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
{\displaystyle \chi^{2}=\sum_{i=1}^{n}{\frac{(O_{i}-E_{i})^{2}}{E_{i}}}=N\sum_{i=1}^{n}{\frac{\left(O_{i}/N-p_{i}\right)^{2}}{p_{i}}}}
\]

\end_inset


\end_layout

\begin_layout Standard
with degree of freedom: The degrees of freedom for a Chi-square grid are
 equal to the number of rows minus one times the number of columns minus
 one: that is, (R-1)*(C-1).
\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Itemize
\begin_inset Formula $O_{i}$
\end_inset

 is the observed number of cases in category i ,
\end_layout

\begin_layout Itemize
\begin_inset Formula $E_{i}$
\end_inset

 is the ex-pected number of cases in category 
\begin_inset Formula $i$
\end_inset

.
 Note that 
\begin_inset Formula $p_{i}=O_{i}/E_{i}$
\end_inset

 no need to be same accross diferent groups.
\end_layout

\begin_layout Standard
This chi square statistic is obtained by calculating the difference between
 the observed number of cases and the expected number of cases in each category.
 This difference is squared and divided by the expected number of cases
 in that category.
 These values are then added for all the categories, and the total is referred
 to as the chi squared value.
\end_layout

\begin_layout Subsection
Chi Square Example 1
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Lyx_Picture/chisquare.png

\end_inset


\end_layout

\begin_layout Itemize
Thus the chi-squared statistic: ((903.3-933)^2/903.3 + (748.5-736)^2 /748.5+
 (709.2-692)^2 /709.2+ (427.7-398)^2/427.7 + (367-354.5)^2/354.5 + (353-335.8)^2/335.8)
 = 4.986582
\end_layout

\begin_layout Itemize
The degrees of freedom for a Chi-square grid are equal to the number of
 rows minus one times the number of columns minus one: that is, (R-1)*(C-1),
 in this case, it is 1*2 = 2.
\end_layout

\begin_layout Standard
What has learned
\end_layout

\begin_layout Itemize
Each sample might be unqiue inself normally.
 Though here the sample 1-3 are all the same group of males, but their 
\begin_inset Formula $N_{i}$
\end_inset

 are (and can be) different: 
\begin_inset Formula $N_{1}$
\end_inset

 is to measure the people in Cov party, 
\begin_inset Formula $N_{2}$
\end_inset

 is for the people in Lab party, etc
\end_layout

\begin_layout Section
Sample Size
\end_layout

\begin_layout Subsection
Minimum sample size
\end_layout

\begin_layout Standard
As the CI for two-sided (total significance level 
\begin_inset Formula $\gamma_{\frac{1}{2}}$
\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
(\hat{p}-\gamma_{\frac{1}{2}}/2\sqrt{\sigma^{2}/n},\hat{p}+\gamma_{\frac{1}{2}}/2\sqrt{\sigma^{2}/n})
\]

\end_inset


\end_layout

\begin_layout Standard
Thus the area of CI / Effective Difference between A and B 
\begin_inset Formula 
\[
CI=\gamma_{\frac{1}{2}}\sqrt{\sigma^{2}/n}
\]

\end_inset


\end_layout

\begin_layout Standard
Thus to require Effective Difference between A and B at certain level 
\begin_inset Formula $CI$
\end_inset

, you need sample size at least
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
n=\frac{\gamma^{2}\sigma^{2}}{CI^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
If you only care about one side, then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
CI=2\gamma\sqrt{\sigma^{2}/n}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
n=\frac{4\gamma^{2}\sigma^{2}}{CI^{2}}
\]

\end_inset


\end_layout

\begin_layout Itemize
The coefficient of 
\begin_inset Formula $\gamma^{2}=16$
\end_inset

 in the formula provides 80% power(10% in each side), i.e., it has an 80%
 probability of rejecting the null hypothesis that there is no difference
 between the Treatment and Control if the true mean is different than the
 true Control by.
 Even a rough estimate of standard deviation in Formula 2 can be helpful
 in planning an experiment.
 
\end_layout

\begin_deeper
\begin_layout Itemize
Replace the 16 by 21 in the formula above to increase the power to 90% (5%
 in each side)
\end_layout

\end_deeper
\begin_layout Itemize
The 
\begin_inset Formula $\Delta=(\bar{O}_{B}-\bar{O}_{A})^{2}$
\end_inset

 is the sensitivity you want to detact, the samller it is, the larger data
 needed,
\end_layout

\begin_layout Standard
Basically, minimum sample size depends on 
\end_layout

\begin_layout Enumerate
Variance
\end_layout

\begin_layout Enumerate
Difference you want to detect: 
\end_layout

\begin_deeper
\begin_layout Enumerate
the more trivial the difference, the larger sample size you need.
\end_layout

\end_deeper
\begin_layout Subsection
Example: impact of lower-variability OEC on the sample size
\end_layout

\begin_layout Standard
Suppose you have an e-commerce site and 5% of users who visit during the
 experiment period end up purchasing.
 Those purchasing spend about $75.
 The average user therefore spends $3.75 (95% spend $0).
 
\end_layout

\begin_layout Standard
We set the OEC = Average Spending = 
\begin_inset Formula $E(S)$
\end_inset

, thus 
\begin_inset Formula $\Delta=\Delta(E(S))$
\end_inset

 = desired change of it
\end_layout

\begin_layout Standard
Assume the standard deviation is 
\begin_inset Formula $\sigma(S)=\$30$
\end_inset

.
 
\end_layout

\begin_layout Standard
If you are running an A/B test and want to detect a 5% change to revenue,
 you will need over 409,000 users to achieve the desired 80% power, based
 on the above formula: 
\begin_inset Formula 
\[
16\times30^{2}/(3.75∗0.05)^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
If, however, you were only looking for a 5% change in conversion rate (not
 revenue), a lower variability OEC based on point 3.b can be used.
 Purchase, a conversion event, is modeled as a Bernoulli trial with p =
 0.05 being the probability of a purchase.
 The standard deviation of a Bernoulli is 
\begin_inset Formula $\sqrt{p(1\text{−}p)}$
\end_inset

 and thus you will need less than 
\series bold

\begin_inset Formula $122,000$
\end_inset


\series default
 users to achieve the desired power based on 
\begin_inset Formula $16\times(0.05·(1−0.05))/(0.05·0.05)^{2}$
\end_inset


\end_layout

\begin_layout Standard

\series bold
The Key Difference here is OEC = Average Conversion Rate has much smaller
 variance than OEC = Average Revenue
\end_layout

\begin_layout Section
Normality Assumption
\end_layout

\begin_layout Section
Power analysis and Sample Design
\end_layout

\begin_layout Standard
Power analysis is an important aspect of experimental design.
 
\end_layout

\begin_layout Standard
It allows us to determine the sample size required to detect an effect of
 a given size with a given degree of confidence.
 Conversely, it allows us to determine the probability of detecting an effect
 of a given size with a given level of confidence, under sample size constraints.
 If the probability is unacceptably low, we would be wise to alter or abandon
 the experiment.
 
\end_layout

\begin_layout Standard
The following four quantities have an intimate relationship: 
\end_layout

\begin_layout Enumerate
sample size 
\end_layout

\begin_layout Enumerate
effect size
\end_layout

\begin_layout Enumerate
significance level = P(Type I error) = probability of finding an effect
 that is not there 
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $\alpha$
\end_inset

 is the threshold of 
\begin_inset Formula $p-value$
\end_inset

, which measures how extreme the observation is.
\end_layout

\begin_layout Enumerate
confidence level: 
\begin_inset Formula $1-\alpha$
\end_inset

: 
\end_layout

\begin_layout Enumerate
single side 
\begin_inset Formula $\alpha=0.05$
\end_inset

 --- z=1.645; single side 
\begin_inset Formula $\alpha=0.01$
\end_inset

 --- z=2.33.
 double side 
\begin_inset Formula $\alpha=0.05$
\end_inset

, or single side 
\begin_inset Formula $\alpha=0.025$
\end_inset

 -- z = 1.96 
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
power = 1 - P(Type II error) = he probability that the test correctly rejects
 the null hypothesis (H0) when the alternative hypothesis (H1) is true.
 
\end_layout

\begin_layout Standard

\series bold
Given any three, we can determine the fourth.
 Thus the first three factors can affect the power of test.
\end_layout

\begin_layout Subsubsection
Effect size
\end_layout

\begin_layout Standard
Effect size measures either measure the sizes of associations or the sizes
 of differences.
 有不同的定义和解释，但大体思想一样。
\end_layout

\begin_layout Enumerate
You already know the most common effect-size measure, as the correlation/regress
ion coefficients r and R are actually measures of effect size.
 Because r covers the whole range of relationship strengths, from no relationshi
p whatsoever (zero) to a perfect relationship (1, or -1), it is telling
 us exactly how large the relationship really is between the variables we've
 studied -- and is independent of how many people were tested.
 Cohen provided rules of thumb for interpreting these effect sizes, suggesting
 that an r of |.1| represents a 'small' effect size, |.3| represents a 'medium'
 effect size and |.5| represents a 'large' effect size.
 
\end_layout

\begin_layout Enumerate
Another common measure of effect size is 
\begin_inset Formula $d$
\end_inset

, sometimes known as 
\series bold
Cohen's 
\begin_inset Formula $d$
\end_inset


\series default
.
 This can be used when comparing two means, as when you might do a t-test,
 and is simply the difference in the two groups' means divided by the average
 of their standard deviations
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
MagnituteEffect=\frac{\mu_{0}-\mu_{A}}{\sigma_{WholeSample}}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Calculate power of test
\end_layout

\begin_layout Standard
Example: We proceed by analyzing D as in a one-sided t-test.
 The null hypothesis will be:
\begin_inset Formula $\mathrm{E}[D]=0$
\end_inset

 (no effect), where 
\begin_inset Formula $\mathrm{E}[]$
\end_inset

 denotes the expected value of a quantity.
 In this case, the alternative is 
\begin_inset Formula $\mathrm{E}[D]>0$
\end_inset

 (positive effect).
 The test statistic is:
\end_layout

\begin_layout Standard
\begin_inset Formula $T=\sqrt{n}\frac{\bar{D}}{\hat{\sigma}_{D}}$
\end_inset

.
 where n is the sample size, 
\begin_inset Formula $\bar{D}$
\end_inset

 is the sample average of the and 
\begin_inset Formula $\hat{\sigma}_{D}^{2}$
\end_inset

 is the sample variance.
 
\end_layout

\begin_layout Standard
Now suppose that the alternative hypothesis is true and 
\begin_inset Formula $\mathrm{E}[D]=\tau$
\end_inset

.
 Then the power is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccl}
\pi(\tau) & = & P(\sqrt{n}\bar{D}/\hat{\sigma}_{D}>1.64|\tau)\\
 & = & P\left(\sqrt{n}(\bar{D}-\tau+\tau)/\hat{\sigma}_{D}>1.64\right|\tau)\\
 & = & P\left(\sqrt{n}(\bar{D}-\tau)/\hat{\sigma}_{D}>1.64-\sqrt{n}\tau/\hat{\sigma}_{D}\right|\tau)
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Note that the above the formula is given 
\begin_inset Formula $\tau$
\end_inset

, thus 
\begin_inset Formula $\sqrt{n}(\bar{D}-\tau)/\hat{\sigma}_{D}$
\end_inset

 follows 
\begin_inset Formula $N(0,1)$
\end_inset

, therefore the power of test is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi(\tau)\approx1-\Phi(1.64-\tau\sqrt{n}/\hat{\sigma}_{D})
\]

\end_inset


\end_layout

\begin_layout Standard
Note that the power of test depends on 
\end_layout

\begin_layout Enumerate
Sample size 
\begin_inset Formula $n$
\end_inset


\end_layout

\begin_layout Enumerate
Effective Size 
\begin_inset Formula $\sqrt{n}(\bar{D}-\tau)/\hat{\sigma}_{D}$
\end_inset


\end_layout

\begin_layout Enumerate
Significance level 
\begin_inset Formula $1.64$
\end_inset


\end_layout

\begin_layout Subsubsection
Balance 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset


\end_layout

\begin_layout Standard
Three ways to increase the power of test.
\end_layout

\begin_layout Enumerate
When increase 
\begin_inset Formula $\alpha$
\end_inset

, you increase Probability of Type 1 error (FP increases).
 But you decrease 
\begin_inset Formula $\beta$
\end_inset

.
 Thus increase the power of test
\end_layout

\begin_layout Enumerate
Magnitude of effect (effect size): the standardized difference between 
\begin_inset Formula $\mu_{0}$
\end_inset

 and 
\begin_inset Formula $\mu_{A}$
\end_inset

.
 The more difference between 
\begin_inset Formula $H_{0}$
\end_inset

 and 
\begin_inset Formula $H_{A}$
\end_inset

, the better.
 
\end_layout

\begin_layout Enumerate
Sample size.
\end_layout

\begin_layout Section
Bayesian vs Frequentist A/B Testing
\end_layout

\begin_layout Part
A/B Test
\end_layout

\begin_layout Enumerate
Randomization Algorithm
\end_layout

\begin_deeper
\begin_layout Enumerate
The algorithm may support 
\series bold
monotonic ramp-up
\series default
, meaning that the percentage of users who see a Treatment can be slowly
 increased without changing the assignments of users who were previously
 assigned to that Treatment.
\end_layout

\begin_layout Enumerate
The algorithm may support external control, meaning that users can be manually
 forced into and out of variants.
 This property makes it easier to test the experimental site.
\end_layout

\end_deeper
\begin_layout Enumerate
Assignment method, uses the output of the randomization algorithm to determine
 the experience that each user will see on the website.
\end_layout

\begin_layout Enumerate
Data path, captures raw observation data as the users interact with the
 website, aggregates it, applies statistics, and prepares reports of the
 experiment’s outcome.
\end_layout

\begin_layout Subsection
Advices
\end_layout

\begin_layout Itemize
The choice of OEC must be made in advance.
 When running experiments, it is important to decide in advance on the OEC
 (a planned comparison); otherwise, there is an increased risk of finding
 what appear to be significant results by chance (familywise type I error)
\end_layout

\begin_layout Section
A/B Test: IV Questions
\end_layout

\begin_layout Itemize
which metric to value a product success
\end_layout

\begin_layout Itemize
how to measure stickness
\end_layout

\begin_layout Itemize
Goal of AB test: Decide the statistical significance you need and also the
 magnitude of the difference, which is the economic difference.
\end_layout

\begin_layout Itemize
After AB test: even 95% significance still means a type 1 error.
\end_layout

\begin_layout Itemize
Not only define the significance level (for type 1 error), also predefine
 the power of test (for type 2 error)
\end_layout

\begin_layout Itemize
multivariate testing: need more data!
\end_layout

\begin_layout Itemize
A/B test didn't answer why/casuality.
\end_layout

\begin_layout Itemize
After you get AB test result, check the time series result to see any annomelies.
 also check whetehr the profiles of two samples are identically distributed.
 e.
\end_layout

\begin_layout Standard
Significance: If the statistical test returns significant, then you conclude
 that the effect is unlikely to arise from random chance alone.
 
\end_layout

\begin_layout Section
Teminology
\end_layout

\begin_layout Standard
https://www.optimizely.com/optimization-glossary/
\end_layout

\begin_layout Itemize
Power.
 The probability of correctly rejecting the null hypothesis, H0, when it
 is false.
 Power measures our ability to detect a difference when it indeed exists.
 
\end_layout

\begin_layout Itemize
Conclusive -- same as Significance
\end_layout

\begin_layout Itemize

\series bold
A/A test
\series default
.
 Sometimes called a 
\series bold
Null Test
\series default
 (Peterson 2004).
 Instead of an A/B test, you exercise the experimentation system, assigning
 users to one of two groups, but expose them to exactly the same experience.
 An A/A test can be used to (i) collect data and assess its variability
 for power calculations, and (ii) test the experimentation system (the Null
 hypothesis should be rejected about 5% of the time when a 95% confidence
 level is used).
\end_layout

\begin_deeper
\begin_layout Itemize
A/A testing is the tactic of using A/B testing to test two identical versions
 of a page against each other.
 Typically, this is done to check that the tool being used to run the experiment
 is statistically fair.
 In an A/A test, the tool should report no difference in conversions between
 the control and variation, if the test is implemented correctly.
\end_layout

\begin_layout Itemize
THINGS TO KEEP IN MIND WITH A/A TESTING
\end_layout

\begin_layout Itemize
When running an A/A test, it’s important to keep in mind that finding a
 difference in conversion rate is always an identical test and control page
 is a possibility.
 This isn’t necessarily a poor reflection on the A/B testing platform, as
 there is always an element of randomness when it comes to testing.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
A/B/n Testing
\end_layout

\begin_deeper
\begin_layout Itemize
A/B/n testing is a type of website testing where multiple versions of a
 web page are compared against each other to determine which has the highest
 conversion rate.
 
\end_layout

\begin_layout Itemize
In addition to helping which version of a page is most successful, A/B/n
 testing also shows which version of a page performed the worst.
 By analyzing these low performing pages, it is possible to come up with
 hypotheses for why certain features convert better than others, and these
 lessons can then be incorporated into new tests on other pages of the site.
\end_layout

\begin_layout Itemize
pitfall: it doesn’t always mean those variables would work well combined.
 Consider running multivariate tests to test all variations and make sure
 that improvements to top level metrics carry all the way through the conversion
 funnel.
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Multivariate testing
\series default
 is more comprehensive than A/B/n testing and is used to test changes to
 specific elements on a page whereas A/B/n testing can be used to test completel
y different versions of a page against each other.
\end_layout

\begin_layout Itemize

\series bold
Effect
\series default
.
 The difference in OECs for the variants, i.e.
 the mean of the Treatment minus the mean of the Control.
 Larger differences are easier to detect, so great ideas will unlikely be
 missed.
 Conversely, Type II errors are more likely when the effects are small.
\end_layout

\begin_layout Section
OEC: Overall Evaluation Criteria
\end_layout

\begin_layout Subsection
OEC with constraints
\end_layout

\begin_layout Standard
From a search engine perspective, degraded algorithmic results (the main
 search engine results shown to users, sometimes referred to as the 10 blue
 links) force people to 
\end_layout

\begin_layout Itemize
issue more queries (increasing queries per user) 
\end_layout

\begin_layout Itemize
click more on ads (increasing revenues)
\end_layout

\begin_layout Standard
So the OEC to insrease revenues cannot be used alone, it shall be comined
 with better user experience, messured by 
\end_layout

\begin_layout Enumerate
Less distinct queries per session
\end_layout

\begin_layout Enumerate
Sessions / User
\end_layout

\begin_layout Standard
This analysis is not just impacting search experiments, but also efforts
 like SEM (Search Engine Marketing).
 When deciding the bid amount for ads to a search engine, it is natural
 to try and optimize for the number of queries in the session that started
 with the ad click.
 However, long sessions may indicate user frustration (e.g., driving users
 to mediocre result pages).
\end_layout

\begin_layout Subsection
Compare ad revenue with the user experience.
\end_layout

\begin_layout Standard
More ads in the front page will decrease the clicks in the second layer
 page, which decreases the revenue.
\end_layout

\begin_layout Standard
1.
 Monetary value that the destination property assigned to a click from the
 MSN home page.
 These destination properties are other sites in the MSN network.
 Such a click generates a visit to an MSN property (e.g., MSN Autos or MSN
 Money), which results in multiple page views.
 
\end_layout

\begin_layout Standard
2.
 The cost paid to search engines for a click that brings a user to an MSNpropert
y but not via the MSN home page (Search Engine Marketing).
 If the home page is driving less traffic to the properties, what is the
 cost of regenerating the “lost” traffic?
\end_layout

\begin_layout Section
Choose Samples
\end_layout

\begin_layout Subsection
Filtering users not impacted by the change
\end_layout

\begin_layout Standard
If you made a change to the checkout process, you should only analyze users
 who started the checkout process (point 3.c), as others could not see any
 difference and therefore just add noise.
\end_layout

\begin_layout Subsection
Treatment ramp-up
\end_layout

\begin_layout Standard
An experiment can be initiated with a small percentage of users assigned
 to the Treatment( s), and then that percentage can be gradually increased.
 For example, if you plan to run an A/B test at 50%/50%, you might start
 with a 99.9%/0.1% split, then rampup the Treatment from 0.1% to 0.5% to 2.5%
 to 10% to 50%.
 
\end_layout

\begin_layout Standard
Benifits
\end_layout

\begin_layout Enumerate
At each step, which could run for, say, a couple of hours, you can analyze
 the data to make sure there are no egregious problems with the Treatment
 before exposing it to more users.
 The square factor (
\begin_inset Formula $\Delta^{2}$
\end_inset

) in the power formula implies that such errors could be caught quickly
 on small populations and the experiment can be aborted before many users
 are exposed to the bad Treatment.
\end_layout

\begin_layout Subsection
Unequal Sample Size test
\end_layout

\begin_layout Itemize
Many implementations of web sites use LRU (least-recently-used) caches throughou
t the stack, so running unequal variants in an A/B test gives an inherent
 speed advantage to the larger variant,
\end_layout

\begin_layout Itemize
But We therefore strongly recommend equally-sized samples in online experimentat
ion.
 
\end_layout

\begin_layout Subsection
Bucket System and Carryover Effects
\end_layout

\begin_layout Standard
Some online experimentation platforms, including at Bing, Google, and Yahoo,
 rely on the “bucket system” to assign users to experiments [3].
 The bucket system randomizes users into different buckets and then assigns
 buckets to experiments.
\end_layout

\begin_layout Itemize
One big drawback with the “bucket system” is its vulnerability to carryover
 effects, where the same users who were impacted by the first experiment
 are being used for the follow-on experiment.

\series bold
 So the impact of the first test will be carried over to the second test.
\end_layout

\begin_layout Itemize
This is known, and A/A tests can be run to check for carryover effects,
 but when they fail, 
\series bold
we lose capacity until we re-randomize the bucket assignment.
\end_layout

\begin_layout Standard
It is clear that there was a 
\series bold
carryover effect
\series default
 on users after the experiment finished.
 The carryover effect seems to die out at about the third week after the
 experiment.
\end_layout

\begin_layout Itemize
So you need a Washout Period
\end_layout

\begin_layout Subsection
Ranom Sampling for Interaction Features in Soccial Network
\end_layout

\begin_layout Standard
Suppose you want to test some interaction features in Messenger: they can
 send stickers rather than pure text message.
 How to choose two samples to run this test.
 
\end_layout

\begin_layout Standard
Note that as this is a scocial network and the sample A and B may have connectio
ns, so enabling A to send stickers means they may send stickers to B, which
 is not allowed for the new feature.
\end_layout

\begin_layout Standard

\series bold
How to solve this problem:
\end_layout

\begin_layout Standard
Just firstr choose a random sample A who are allowed to send out stickers
 and run the test for a week.
\end_layout

\begin_layout Standard
After the week, look at historical data and 
\end_layout

\begin_layout Section
Duration / Time of Test
\end_layout

\begin_layout Subsection
Beware of day of week effects
\end_layout

\begin_layout Standard
We would then recommend running it for a week to avoid day-of-week effects
 and to increase the power over the minimum.
 However, if the experiment were run at 95%/5%, the running time would have
 to be increased by a factor of 5–25 days, in which case we would recommend
 running it for four weeks.
\end_layout

\begin_layout Subsection
Primacy and Novelty effect 
\end_layout

\begin_layout Itemize
Primacy effect occurs when you change the navigation on a web site, and
 experienced users may be less efficient until they get used to the new
 navigation, thus giving an inherent advantage to the Control.
\end_layout

\begin_layout Itemize
Novelty effect: when a new design or feature is introduced, some users will
 investigate the new feature, click everywhere, and thus introduce a “novelty”
 bias that dies quickly if the feature is not truly useful.
\end_layout

\begin_layout Standard
So be aware of any trend pattern by time, you need to wait longer time till
 the trend stabalized and then evaluate.
\end_layout

\begin_layout Subsection
Short Term versus Long Term Effects: Delayed OEC
\end_layout

\begin_layout Standard
Short term versus long term effects.
 Controlled experiments measure the effect on the OEC during the experimentation
 period, typically a few weeks.
\end_layout

\begin_layout Enumerate
Long-term goals should be part of the OEC.
 Let us take search ads as an example.
 If your OEC is revenue, you might plaster ads over a page, but we know
 that many ads hurt the user experience, so a good OEC should include a
 penalty term of usage of real-estate for ads that are not clicked, and/or
 should directly measure repeat visits and abandonment.
 
\end_layout

\begin_layout Enumerate
Likewise, it is wise to look at 
\series bold
Delayed conversion metrics
\series default
, where there is a lag from the time a user is exposed to something and
 take action.
 
\end_layout

\begin_deeper
\begin_layout Enumerate
If you change the navigation on a web site, experienced users may be less
 efficient until they get used to the new navigation, thus giving an inherent
 advantage to the Control.
\end_layout

\end_deeper
\begin_layout Standard
These are sometimes called latent conversions (Miller 2006; Quarto-vonTivadar
 2006).
 Coming up with good OECs is hard, but what is the alternative? The key
 point here is to recognize this limitation, but avoid throwing the baby
 out with the bathwater.
\end_layout

\begin_layout Section
Effect Analysis
\end_layout

\begin_layout Subsection
Machine Learning and Data Mining
\end_layout

\begin_layout Standard
For example, an experiment showed no significant difference overall, but
 a population of users with a specific browser version was significantly
 worse for the Treatment.
 The specific Treatment feature, which involved JavaScript, was buggy for
 that browser version and users abandoned.
 Excluding the population from the analysis showed positive results, and
 once the bug was fixed, the feature was indeed retested and was positive
\end_layout

\begin_layout Section
Culture and business
\end_layout

\begin_layout Standard
It is difficult to get a man to understand something when his salary depends
 upon his not understanding it.
\end_layout

\begin_layout Standard

\series bold
“Do it Wrong Quickly”: test quickly, report quickly, decision quickly.
\end_layout

\begin_layout Subsection
Internet Speed matters
\end_layout

\begin_layout Standard
A Treatment might provide a worse user experience because of its performance.
 Linden (2006b, p.
 15), wrote that experiments at Amazon showed a 1% sales decrease for an
 additional 100msec, and that a specific experiment at Google, which increased
 the time to display search results by 500 msecs reduced revenues by 20%
 (based on a talk byMarissa Mayer atWeb 2.0).
\end_layout

\begin_layout Itemize
So a fancy feature may be bad today, but better years later when internet
 speed is higher.
\end_layout

\begin_layout Subsection

\series bold
HiPPO attack
\end_layout

\begin_layout Standard
Linsky and Heifetz wrote that “People do not resist change, per se.
 People resist loss” (Linsky & Heifetz, 2002).
 Some people certainly viewed experimentation as a risk to their power and/or
 prestige.
\end_layout

\begin_layout Standard
What we found was that a great way to convince people that we are not good
 at predicting the outcomes of experiment is to challenge them.
 We created a survey with eight A/B tests, and offered a nice polo shirt
 for anyone who could correctly guess 6 out of 8 (the options were: A is
 statistically significantly better, B is statistically significantly better,
 or there’s no statistically significant difference between them).
 With over 200 responses, we didn’t have to hand out a single shirt! 6 out
 of 200 had 5 answers correct; the average was 2.3 correct answers
\end_layout

\begin_layout Section
Applications
\end_layout

\begin_layout Section
Multivariate Testing
\end_layout

\begin_layout Standard
An experiment that includes more than one factor is often called a MultiVariable
 test (MVT) (Alt and Usborne 2005).
 For example, consider testing five factors on theMSN homepage in a single
 experiment.
 we will consider the benefits and limitations of MVT versus one-factor-at-a-tim
e, or A/B tests.
 Then we will discuss three approaches to online MVTs and how each approach
 takes advantage of the potential benefits and mitigates the limitations.
\end_layout

\begin_layout Subsection
Example
\end_layout

\begin_layout Standard
As an example: Run a multivariate test on one of your landing pages and
 change it with two new elements.
 On the first version, add a contact form instead of the main image.
 On the second version, add a video item.
 The system will now generate another possible combination based on your
 changes, which includes both the video and the contact form:
\end_layout

\begin_layout Standard
To get a full factorial test: Total test versions = 2 x 2 = 4:
\end_layout

\begin_layout Standard
V1 Control variation (no contact form and no video item) V2 Contact form
 version V3 Video item version V4 Contact form + video item version
\end_layout

\begin_layout Subsection
Advantage/ Limitations compared with AB test
\end_layout

\begin_layout Standard
Advantage
\end_layout

\begin_layout Enumerate
You can test many factors in a short period of time, accelerating improvement.
\end_layout

\begin_layout Enumerate
You can estimate interactions between factors.
 Two factors interact if their combined effect is different from the sumof
 the two individual effects.
\end_layout

\begin_deeper
\begin_layout Enumerate
If the two factors work together to enhance the outcome the interaction
 is synergistic.
 
\end_layout

\begin_layout Enumerate
If instead they work against each other to dampen the effect, the interaction
 is antagonistic.
\end_layout

\end_deeper
\begin_layout Standard
Limitations
\end_layout

\begin_layout Enumerate
interaction is antagonistic.
 /æn,tæɡə'nɪstɪk/
\end_layout

\begin_layout Enumerate
Analysis and interpretation are more difficult.
\end_layout

\begin_layout Subsection
Full factorial experiment
\end_layout

\begin_layout Standard
Grouop number = N, If each group has two options, then the total combinations
 are 
\begin_inset Formula $2^{N}$
\end_inset

.
 Of course, with a full factorial you will be able to estimate any interaction
 you want.
\end_layout

\begin_layout Subsection
Interactions
\end_layout

\begin_layout Standard
In the statistical field of Design of Experiments, a major research area
 is to find designs that minimize the number of user groups needed for the
 test while allowing you to estimate the main effects and interactions with
 little or no confounding.
\end_layout

\begin_layout Part
Multi-Armed Bandit 
\end_layout

\begin_layout Standard
http://conversionxl.com/bandit-tests/
\end_layout

\begin_layout Itemize
A/B testing explores first then exploits (keeps only winner): 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Lyx_Picture/abtest.jpg

\end_inset


\end_layout

\begin_layout Itemize
Bandit testing tries to solve the explore-exploit problem in a different
 way.
 Instead of two distinct periods of pure exploration and pure exploitation,
 bandit tests are adaptive, and simultaneously include exploration and exploitat
ion.
 
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Lyx_Picture/bandit.jpg

\end_inset


\end_layout

\begin_layout Itemize

\series bold
Goal
\series default
:
\end_layout

\begin_deeper
\begin_layout Itemize
Choose the 
\series bold
correct
\series default
 version 
\series bold
quickly
\series default
.
\end_layout

\begin_layout Itemize
So, bandit algorithms try to minimize opportunity costs and minimize regret
 (the difference between your actual payoff and the payoff you would have
 collected had you played the optimal (best) options at every opportunity.).
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Weakness / Trade - off
\end_layout

\begin_deeper
\begin_layout Itemize
http://conversionxl.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-09-at-3.49.4
5-PM-1.jpg
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
Intuition
\end_layout

\begin_deeper
\begin_layout Itemize
Earning while learning
\end_layout

\end_deeper
\begin_layout Subsection

\series bold
Usage
\end_layout

\begin_layout Itemize
Used for short Testing / News / Short term campaign.
 Not enough time for AB test to collect data.
\end_layout

\begin_layout Itemize
Used for on-going test: 
\end_layout

\begin_deeper
\begin_layout Itemize
Suppose you’re running a news site, and you want to determine the best order
 to display the top 5 sports stories everyday.
\end_layout

\begin_layout Itemize
A/B tests also fall short for ongoing tests – in particular, where the test
 is constantly evolving.
 
\end_layout

\end_deeper
\begin_layout Itemize
“Set it and forget it” (Automation for Scale)
\end_layout

\begin_layout Subsection
When To Use Bandit Tests Instead of A/B/n Tests?
\end_layout

\begin_layout Standard
There’s a high level answer, and then there are some specific circumstances
 in which bandit works well.
 For the high level answer, if you have a research question where you want
 to understand the effect of a treatment and have some certainty around
 your estimates, a standard a/b test experiment will be best.
\end_layout

\begin_layout Standard
According to Matt Gershoff, “If on the other hand, you actually care about
 optimization, rather than understanding, bandits are often the way to go.”
\end_layout

\begin_layout Subsection

\series bold
Usage Example
\end_layout

\begin_layout Standard
For example, if we wish to test which of three titles works for an article
 on a news website, we know that the article will be featured on our front
 page for a few hours only.
 This means we have to quickly detect the better performing title and also
 exploit that knowledge within the timeframe of a few hours.
 In this case, we can use a multi-armed bandit approach, which helps us
 do just that.
 In short, this approach continuously splits the traffic between the variations
 according to the performance measured so far and the level of certainty
 gained each step of the way.
 This approach trades-off some of the certainty about which is “really”
 the best variation in exchange for quicker convergence.
 
\end_layout

\begin_layout Subsection
Benifits
\end_layout

\begin_layout Itemize
Earn While You Learn.
 Data collection is a cost, and bandit approach at least lets us consider
 these costs while running optimization projects.
\end_layout

\begin_layout Itemize
Automation.
 Bandits are the natural way to automate the selection optimization with
 machine learning, especially when applying user target – since correct
 a/b tests are much more complicated in that situation.
\end_layout

\begin_layout Itemize
A Changing World.
 Matt explains that by letting the bandit method always leave some chance
 to select the poorer performing option, you give it a chance to ‘reconsider’
 the option effectiveness.
 It provides a working framework for swapping out low performing options
 with fresh options, in a continuous process.
\end_layout

\begin_layout Subsection
Assumptions
\end_layout

\begin_layout Description
a) Conversion rates don’t change over time.
\end_layout

\begin_layout Description
b) Displaying a variation and observing a conversion happen instantaneously.
 This means the following timeline is impossible: 12:00 Visitor A sees Variation
 1.
 12:01 visitor B sees Variation 2.
 12:02 Visitor A converts.
\end_layout

\begin_layout Description
c) Samples in the bandit algorithm are independent of each other.
\end_layout

\begin_layout Standard
A/B testing is a fairly robust algorithm when these assumptions are violated.
 A/B testing doesn’t care much if conversion rates change over the test
 period – i.e., if Monday is different from Saturday, just make sure your
 test has the same number of Mondays and Saturdays and you are fine.
 
\series bold
Similarly, as long as your test period is long enough to capture conversions,
 again – it’s all good.”
\end_layout

\begin_layout Subsection
Epsilon-Greedy Method
\end_layout

\begin_layout Itemize
In computer science, a greedy algorithm is one that always takes the action
 that seems best at that moment.
\end_layout

\begin_layout Itemize
So, an 
\series bold
epsilon-greedy algorithm
\series default
 is almost a fully greedy algorithm – most of the time (90% of time, but
 not time) it picks the option that makes sense at that moment.
\end_layout

\begin_layout Itemize

\series bold
Usage: 10% of the time, we choose a lever at random.
 The other 90% of the time, we choose the lever that has the highest expectation
 of rewards.”
\end_layout

\begin_deeper
\begin_layout Itemize
Maybe you Should decrease exploration over time?
\end_layout

\end_deeper
\begin_layout Itemize
to ensure that the system doesn’t early converge to a sub-optimal solution.
 
\end_layout

\begin_layout Standard
It gives potentially inferior the oppotunity to turn aound, as you may be
 wrong in the begining
\end_layout

\begin_layout Section
Algorithm: Thompson sampling
\end_layout

\begin_layout Standard
Consider a set of contexts X , a set of actions A , and rewards in R .
 In each round, the player obtains a context x ∈ X , plays an action a ∈
 A and receives a reward r ∈ R following a distribution that depends on
 the context and the issued action.
 The aim of the player is to play actions such as to maximize the cumulative
 rewards.
\end_layout

\begin_layout Enumerate
The elements of Thompson sampling are as follows:
\end_layout

\begin_layout Enumerate
a likelihood function 
\begin_inset Formula $P(r|\theta,a,x)$
\end_inset

;
\end_layout

\begin_layout Enumerate
a set 
\begin_inset Formula $\Theta$
\end_inset

 of parameters θ 
\begin_inset Formula $\theta$
\end_inset

 of the distribution of 
\begin_inset Formula $r$
\end_inset

;
\end_layout

\begin_layout Enumerate
a prior distribution 
\begin_inset Formula $P(\theta)$
\end_inset

 on these parameters;
\end_layout

\begin_layout Enumerate
past observations triplets D = { ( x ; a ; r ) } {
\begin_inset Formula ${\displaystyle D=\{(x;a;r)\}}$
\end_inset

} {
\backslash
mathcal {D}}=
\backslash
{(x;a;r)
\backslash
};
\end_layout

\begin_layout Enumerate
a posterior distribution 
\begin_inset Formula ${\displaystyle P(\theta|\mathcal{D})\propto P(\mathcal{D}|\theta)P(\theta)}$
\end_inset

, where P ( D | θ ) is the likelihood function.
\end_layout

\begin_layout Standard
Thompson sampling consists in playing the action {
\begin_inset Formula ${\displaystyle a^{\ast}\in\mathcal{A}}$
\end_inset

} according to the probability that it maximizes the expected reward, i.e.
\begin_inset Formula 
\[
{\displaystyle \int\mathbb{I}[\mathbb{E}(r|a,x,\theta)=\max_{a'}\mathbb{E}(r|a',x,\theta)]P(\theta|{\mathcal{D}})\,d\theta,}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathbb{I}$
\end_inset

 is the indicator function.
\end_layout

\begin_layout Standard
In practice, the rule is implemented by sampling, in each round, a parameter
 θ 
\begin_inset Formula $\theta^{\ast}$
\end_inset

 from the posterior 
\begin_inset Formula $P(\theta|\mathcal{D})$
\end_inset

, and choosing the action 
\begin_inset Formula $a^{\ast}$
\end_inset

 that maximizes
\begin_inset Formula ${\displaystyle \mathbb{E}[r|\theta^{\ast},a^{\ast},x]}$
\end_inset

 ], i.e.
 the expected reward given the parameter, the action and the current context.
 Conceptually, this means that the player instantiates his beliefs randomly
 in each round, and then he acts optimally according to them.
\end_layout

\begin_layout Section
Contextual Bandits
\end_layout

\begin_layout Standard
http://hunch.net/?p=298
\end_layout

\begin_layout Standard
A standard mathematical setting for this situation is “k-Armed Bandits”,
 often with various relevant embellishments.
 The k-Armed Bandit setting works on a round-by-round basis.
 On each round:
\end_layout

\begin_layout Standard
A policy chooses arm a from 1 of k arms (i.e.
 1 of k ads).
\end_layout

\begin_layout Standard
The world reveals the reward ra of the chosen arm (i.e.
 whether the ad is clicked on).
\end_layout

\begin_layout Standard
As information is accumulated over multiple rounds, a good policy might
 converge on a good choice of arm (i.e.
 ad).
\end_layout

\begin_layout Standard
This setting (and its variants) fails to capture a critical phenomenon:
 each of these displayed ads are done in the context of a search or other
 webpage.
 To model this, we might think of a different setting where on each round:
\end_layout

\begin_layout Standard
The world announces some context information x (think of this as a high
 dimensional bit vector if that helps).
\end_layout

\begin_layout Standard
A policy chooses arm a from 1 of k arms (i.e.
 1 of k ads).
\end_layout

\begin_layout Standard
The world reveals the reward ra of the chosen arm (i.e.
 whether the ad is clicked on).
\end_layout

\begin_layout Standard
We can check that this is a critical distinction in 2 ways.
 First, note that policies using x can encode much more rich decisions than
 a policy not using x.
 Just think about: “if a search has the word flowers display a flower advertisem
ent”.
 Second, we can try to reduce this setting to the k-Armed Bandit setting,
 and note that it can not be done well.
 There are two methods that I know of:
\end_layout

\begin_layout Standard
Run a different k-Armed Bandit for every value of x.
 The amount of information required to do well scales linearly in the number
 of contexts.
 In contrast, good supervised learning algorithms often require information
 which is (essentially) independent of the number of contexts.
\end_layout

\begin_layout Standard
Take some set of policies and treat every policy h(x) as a different arm.
 This removes an explicit dependence on the number of contexts, but it creates
 a linear dependence on the number of policies.
 Via Occam’s razor/VC dimension/Margin bounds, we already know that supervised
 learning requires experience much smaller than the number of policies.
\end_layout

\begin_layout Standard
We know these are bad reductions by contrast to direct methods for solving
 the problem.
 The first algorithm for solving this problem is EXP4 (page 19 = 66) which
 has a regret with respect to the best policy in a set of O( T0.5 (ln |H|)0.5)
 where T is the number of rounds and |H| is the number of policies.
 (Dividing by T gives error-rate like quantities.) This result is independent
 of the number of contexts x and only weakly dependent (similar to supervised
 learning) on the number of policies.
\end_layout

\begin_layout Part
ANOVA
\end_layout

\begin_layout Standard
Here we do not focus on OLS, but focus on experiment design: different trails
 on different groups and compare the result.
\end_layout

\begin_layout Itemize

\series bold
Analysis of variance (ANOVA):
\series default
 is a collection of statistical models used to analyze the differences between
 group means and their associated procedures.
 
\end_layout

\begin_layout Itemize

\series bold
Design of experiments (DOE):
\series default
 or experimental design is the design of any information-gathering exercises
 where variation is present, whether under the full control of the experimenter
 or not.
 
\end_layout

\begin_layout Standard
Example: find the most important factors to explain dogs' weight 
\begin_inset Foot
status open

\begin_layout Plain Layout
http://en.wikipedia.org/wiki/Analysis_of_variance
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
An attempt to explain the weight distribution by grouping dogs as (pet vs
 working breed) and (less athletic vs more athletic) would probably be somewhat
 more successful (fair fit).
 If just use http://en.wikipedia.org/wiki/File:ANOVA_fair_fit.jpg
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Lyx_Picture/ANOVA_fair_fit.jpg
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Itemize
An attempt to explain weight by breed is likely to produce a very good fit.
 All Chihuahuas are light and all St Bernards are heavy.
 The difference in weights between Setters and Pointers does not justify
 separate breeds.
 http://en.wikipedia.org/wiki/File:ANOVA_very_good_fit.jpg
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename Lyx_Picture/ANOVA_very_good_fit.jpg
	lyxscale 80
	scale 80

\end_inset


\end_layout

\begin_layout Subsection
Terminology
\end_layout

\begin_layout Itemize
Treatment: 
\end_layout

\begin_deeper
\begin_layout Itemize
In an experiment, the factor (also called an independent variable) is an
 explanatory variable manipulated by the experimenter.
 
\end_layout

\begin_layout Itemize
Each factor has two or more levels, i.e., different values of the factor.
 Combinations of factor levels are called treatments.
 The table below shows independent variables, factors, levels, and treatments
 for a hypothetical experiment.
\end_layout

\end_deeper
\begin_layout Subsection
Variations
\end_layout

\begin_layout Enumerate
Explained = Between Group = Treatment
\end_layout

\begin_layout Enumerate
Unexplained = Error = Within Group
\end_layout

\begin_layout Itemize
Intuition: 
\end_layout

\begin_deeper
\begin_layout Itemize
We use different factors/treatments to separate different groups.
 The only way to judge the explainability of those factors/treatments are
 to look at whether those groups have different means.So that Explained SS
 = Between Group SS = Treatment SS.
\end_layout

\begin_layout Itemize
Within one group, as they are have the same factors/treatments, so that
 we can not explain them.
 Thus Unexplained = Error = Within Group.
 
\end_layout

\end_deeper
\begin_layout Subsubsection
Partitioning of Variations
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
SS_{total}=SS_{error}+SS_{explain}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
DF_{total}=DF_{error}+DF_{explain}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Within Group variation v.s.
 Between Group variation.
\end_layout

\begin_layout Standard
where 
\begin_inset Formula $SS_{explain}$
\end_inset

 is also called 
\begin_inset Formula $SS_{treatment}$
\end_inset

 in experimental design.
 Intuition: the effect of any treatment is estimated by taking the difference
 between the mean of the observations which receive the treatment and the
 general mean
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
SS_{BetweenGroup}=\sum_{i}n_{i}(\bar{Y}{}_{i}-\bar{Y})^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
with 
\begin_inset Formula $DF_{BetweenGroup}=K-1$
\end_inset

 (number of groups minus 1).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
SS_{withinGroup_{i}}=\sum_{j=1}^{n_{i}}(y_{i,j}-\bar{Y}_{i})^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $DF_{i}=n_{i}-1$
\end_inset

 (df of group 
\begin_inset Formula $i$
\end_inset

 is its freq -1 ).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
SS_{withinGroup}=\sum_{i}SS_{withGroup_{i}}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $DF_{withinGroup}=\sum_{i}DF_{i}=N-K$
\end_inset


\end_layout

\begin_layout Subsection
RSS, RSE and 
\begin_inset Formula $R^{2}$
\end_inset


\end_layout

\begin_layout Standard
We choose β0, β1, .
 .
 .
 , βp to minimize the sum of squared residuals
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
RSS=\sum(y_{i}-y_{0})^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Recall from the model (3.5) that associated with each observation is an error
 term ε.
 Due to the presence of these error terms, even if we knew the true regression
 line (i.e.
 even if β0 and β1 were known), we would not be able to perfectly predict
 Y from X.
 RSE is the estimate of std of the error term
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
RSE=\sqrt{\frac{1}{N-p-1}RSS}
\]

\end_inset


\end_layout

\begin_layout Standard
The RSE provides an absolute measure of lack of fit of the model (3.5) to
 the data.
 But since it is measured in the units of Y , it is not always clear what
 constitutes a good RSE.
 The R2 statistic provides an alternative measure of fit.
 It takes the form of a proportion 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
R^{2}=\frac{TSS-RSS}{TSS}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $TSS=\sum(y_{0}-\bar{y})^{2}$
\end_inset


\end_layout

\begin_layout Subsection
Nested ANOVA
\end_layout

\begin_layout Standard
\begin_inset Foot
status open

\begin_layout Plain Layout
library(effects)
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
glm(volunteer ~ sex:extraversion + extraversion + sex,data=Cowles, family=binomi
al) 
\end_layout

\begin_deeper
\begin_layout Enumerate
This model is Full ANOVA, as in this model we include cross-group variation
 and within group variation for both variables 
\end_layout

\end_deeper
\begin_layout Enumerate
glm(volunteer ~ sex:extraversion + extraversion,data=Cowles, family=binomial)
\end_layout

\begin_deeper
\begin_layout Enumerate
in this model, we restrict that extraversion is nested in sex, which means
 extraversion is just a subgroup within each sex.
 Thus the ANOVA table will also be different See details at
\end_layout

\begin_layout Enumerate

\emph on
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://www.biostat.wisc.edu/~kbroman/teaching/labstat/fourth/notes11.pdf
\end_layout

\end_inset


\end_layout

\end_deeper
\begin_layout Subsection
Multiple Group: F-test
\end_layout

\begin_layout Standard
This is also called One-way ANOVA.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
F & = & \frac{ExplainedVariation}{UNexplainedVariation}=\frac{BetweenGroupVariation}{WithinGroupVariation}\\
 & = & \frac{SS_{explianed}/DF_{explained}}{SS_{unexplianed}/DF_{unexplained}}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Itemize
Note that when there are only two groups for the one-way ANOVA F-test, F
 test is same as 
\begin_inset Formula $T$
\end_inset

 test, as in that case 
\begin_inset Formula $F=t^{2}$
\end_inset

 where t is the Student's t statistic.
\end_layout

\begin_layout Subsubsection
Assumptions and Robustness
\end_layout

\begin_layout Enumerate
Normality – the distributions of the residuals are normal.
 
\end_layout

\begin_layout Enumerate
Equality (or "homogeneity") of variances, called homoscedasticity — the
 variance of data in groups should be the same.
\end_layout

\begin_layout Standard

\emph on
http://en.wikipedia.org/wiki/F-test:
\emph default
 The general conclusion from these studies is that the consequences of such
 violations are less severe than previously thought.
 Although these conclusions should not entirely discourage anyone from being
 concerned about the normality assumption, they have increased the overall
 popularity of the distribution-dependent statistical tests in all areas
 of research."[9] 
\begin_inset Foot
status open

\begin_layout Plain Layout
https://www.statsoft.com/textbook/elementary-statistics-concepts/
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection

\series bold
In Experimental Design:
\end_layout

\begin_layout Itemize

\series bold
The F-test in one-way analysis of variance is used to assess whether the
 expected values of a quantitative variable within several pre-defined groups
 differ from each other.
 
\end_layout

\begin_layout Itemize
For example, suppose that a medical trial compares four treatments.
 The ANOVA F-test can be used to assess whether any of the treatments is
 on average superior, or inferior, to the others versus the null hypothesis
 that all four treatments yield the same mean response.
 
\end_layout

\begin_layout Itemize
The advantage of the ANOVA F-test is that we do not need to pre-specify
 which treatments are to be compared, and we do not need to adjust for making
 multiple comparisons.
 
\end_layout

\begin_layout Subsubsection
F-test in OLS
\end_layout

\begin_layout Standard
Used to test differences between nested models, to see whether the full
 model is better than simpler model.
 
\begin_inset Formula $H_{0}$
\end_inset

: all additional coefficients have 
\begin_inset Formula $\beta=0$
\end_inset


\end_layout

\begin_layout Subsection
Two Group: Welch's t-test 
\end_layout

\begin_layout Itemize
Welch's t-test is a derivation of t-test.
 It is used in the cases of unequal variance / unequal sample sizes.
\end_layout

\begin_layout Standard
Note that when there are only two groups for the one-way ANOVA F-test, F=t2
 where t is the Student's t statistic.
\end_layout

\begin_layout Standard
Pooled standard deviation: (see p9 Text_How to Measure Quality of Credit
 Scoring Models)
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S_{pooled}^{2}=\frac{nS_{1}^{2}+mS_{2}^{2}}{n+m}
\]

\end_inset


\end_layout

\begin_layout Standard
Thus the test statistics for difference between means is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
D=\frac{M_{g}-M_{b}}{S_{pooled}}
\]

\end_inset


\end_layout

\begin_layout Itemize
ANOVA in comparing two OLS models (essentially F-test) can be found in ANOVA
 section in GLM chapter.
\end_layout

\begin_layout Part
Web Techs
\end_layout

\begin_layout Standard
Some changes will affect the web beacon which increases the successes of
 recording clicks, not the true number of clicks.
\end_layout

\begin_layout Standard
In the video world, latency is the amount of time between the instant a
 frame is captured and the instant that frame is displayed.
 Low latency is a design goal for any system where there is real-time interactio
n with the video content, such as video conferencing or drone piloting.
 http://www.cast-inc.com/blog/white-paper-understanding-and-reducing-latency-in-vi
deo-compression-systems
\end_layout

\end_body
\end_document
